import openai
import torch
from ElasticSearch.Get_data import get_data_from_es
from model import create_tfidf_model, create_bert_model, search_combined




# OpenAI API Key
openai.api_key = "YOUR API KEY HERE"
# XÃ¡c Ä‘á»‹nh thiáº¿t bá»‹ (GPU náº¿u cÃ³)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

print("ğŸ”„ Äang táº£i dá»¯ liá»‡u tá»« Elasticsearch...")
documents = get_data_from_es()
print("ğŸ”„ Äang táº¡o mÃ´ hÃ¬nh TF-IDF vÃ  BERT...")
tfidf_matrix_title, tfidf_matrix_content, vectorizer_title, vectorizer_content = create_tfidf_model(documents)
embeddings, model = create_bert_model(documents)


def search_info(query):
    """
    TÃ¬m kiáº¿m thÃ´ng tin liÃªn quan báº±ng TF-IDF + BERT
    """
    results = search_combined(query, vectorizer_title, vectorizer_content,
                              tfidf_matrix_title, tfidf_matrix_content,
                              model, embeddings, documents)

    if results:
        best_result = results[0]  # Láº¥y káº¿t quáº£ tá»‘t nháº¥t
        context = best_result["title"] + "\n" + best_result["content"]
    else:
        context = ""

    return context


def generate_response_with_gpt(query, context=""):
    """
    Gá»­i query Ä‘áº¿n GPT-3.5-turbo, náº¿u cÃ³ context thÃ¬ sá»­ dá»¥ng Ä‘á»ƒ tráº£ lá»i tá»‘t hÆ¡n.
    """
    prompt = f"""
    Báº¡n lÃ  má»™t trá»£ lÃ½ AI. HÃ£y tráº£ lá»i cÃ¢u há»i dá»±a trÃªn thÃ´ng tin sau náº¿u cÃ³:

    CÃ¢u há»i: {query}

    {("ThÃ´ng tin liÃªn quan:\n" + context) if context else ""}
    """
    client = openai.OpenAI(api_key=openai.api_key)
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "system", "content": "Báº¡n lÃ  má»™t trá»£ lÃ½ AI."},
                  {"role": "user", "content": prompt}],
        max_tokens=500
    )

    return response.choices[0].message.content.strip()


def chatbot():
    """
    VÃ²ng láº·p chatbot: nháº­p cÃ¢u há»i tá»« terminal vÃ  nháº­n cÃ¢u tráº£ lá»i tá»« GPT.
    """
    print("ğŸš€ Chatbot AI (Nháº­p 'exit' Ä‘á»ƒ thoÃ¡t)\n")
    while True:
        query = input("ğŸ’¬ Nháº­p cÃ¢u há»i: ").strip()
        if query.lower() == "exit":
            print("ğŸ‘‹ Táº¡m biá»‡t!")
            break

        # ğŸ” TÃ¬m kiáº¿m thÃ´ng tin báº±ng TF-IDF + BERT
        context = search_info(query)

        # ğŸ¤– GPT tráº£ lá»i dá»±a trÃªn thÃ´ng tin tÃ¬m Ä‘Æ°á»£c
        response = generate_response_with_gpt(query, context)
        print("\nğŸ“Œ Chatbot Response:\n", response)


if __name__ == "__main__":
    chatbot()
